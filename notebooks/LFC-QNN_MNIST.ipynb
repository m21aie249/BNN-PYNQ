{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNN on Pynq\n",
    "\n",
    "This notebook covers how to use low quantized Neural Networks on Pynq for inference on MNIST dataset by using LFC network composed of 4 fully connected layers with 1024 neurons each. There are 2 networks using different precision: \n",
    "\n",
    "- LFCW1A1 using 1 bit weights and 1 activation,\n",
    "- LFCW1A2 using 1 bit weights and 2 activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LFC and MNIST\n",
    "\n",
    "This notebook performs inference on MNIST test set from http://yann.lecun.com/exdb/mnist/ which contains 10000 pictures of handwritten digits. The LFC network requires MNIST formatted input data, that's why the binary test file can be directly loaded. All other images have to be formatted to this specification (refer to url and LFC webcam examples).\n",
    "\n",
    "At first you need to download mnist test set and labels using wget and unzip the archive as shown below:\n",
    "In order to be able to compare the inferred classes against the expected labels we first read the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-14 16:36:44--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 2606:4700:83be:3811:880d:b:be93:f32b, 172.67.171.76, 104.21.29.36\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|2606:4700:83be:3811:880d:b:be93:f32b|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648877 (1.6M) [application/x-gzip]\n",
      "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
      "\n",
      "t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-04-14 16:36:45 (13.2 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
      "\n",
      "--2023-04-14 16:36:45--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 2606:4700:83be:3811:880d:b:be93:f32b, 172.67.171.76, 104.21.29.36\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|2606:4700:83be:3811:880d:b:be93:f32b|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4542 (4.4K) [application/x-gzip]\n",
      "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
      "\n",
      "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-04-14 16:36:45 (6.73 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz \n",
    "#unzip    \n",
    "!gzip -df t10k-images-idx3-ubyte.gz\n",
    "!gzip -df t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "#read labels\n",
    "labels = []\n",
    "with open(\"/home/xilinx/jupyter_notebooks/bnn/t10k-labels-idx1-ubyte\",\"rb\") as lbl_file:\n",
    "    #read magic number and number of labels (MSB first) -> MNIST header\n",
    "    magicNum = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    countLbl = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    #now the labels are following byte-wise\n",
    "    for idx in range(countLbl):\n",
    "        labels.append(int.from_bytes(lbl_file.read(1), byteorder=\"big\"))\n",
    "    lbl_file.close()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardware Inference\n",
    "\n",
    "First of all a classifier needs to be instantiated. Using the LfcClassifier will allow to classify MNIST formatted images utilizing LFC network. There are two different runtimes available: hardware accelerated and pure software environment.\n",
    "\n",
    "Once a classifier is instantiated the inference on MNIST images can be started using `classify_mnist` or `classify_mnists` methods - for both single and multiple images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: \n",
    "##### W1A1 - 1 bit weights and 1 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting network weights and thresholds in accelerator...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfcW1A1_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1,\"mnist\",bnn.RUNTIME_HW)\n",
    "lfcW1A1_classifier.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prebinarized test for 10000 images...\n",
      "Inference took 84120 microseconds, 8.412 usec per image\n",
      "Classification rate: 118878 images per second\n",
      "Inference took 84120.00 microseconds, 8.41 usec per image\n",
      "Classification rate: 118877.80 images per second\n"
     ]
    }
   ],
   "source": [
    "result_W1A1 = lfcW1A1_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: \n",
    "#### W1A2 - 1 bit weights and 2 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting network weights and thresholds in accelerator...\n"
     ]
    }
   ],
   "source": [
    "lfcW1A2_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A2,\"mnist\",bnn.RUNTIME_HW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prebinarized test for 10000 images...\n",
      "Inference took 84118 microseconds, 8.4118 usec per image\n",
      "Classification rate: 118881 images per second\n",
      "Inference took 84118.00 microseconds, 8.41 usec per image\n",
      "Classification rate: 118880.61 images per second\n"
     ]
    }
   ],
   "source": [
    "result_W1A2 = lfcW1A2_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Software accelerated inference\n",
    "\n",
    "In comparison to previous runs the inference can be performed in pure software runtime utilizing PYNQs ARM core. Let's only take the first 10 pictures to get results within a narrow time frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\", \"wb\") as out_file:\n",
    "    with open(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\",\"rb\") as img_file:\n",
    "        #copy magic number\n",
    "        out_file.write(img_file.read(4))\n",
    "        #set number of images\n",
    "        img_file.read(4)\n",
    "        out_file.write(bytearray.fromhex('0000000A'))        \n",
    "        #copy row and column information\n",
    "        out_file.write(img_file.read(8))\n",
    "        \n",
    "        #copy 10 pictures (one is 28x28, 1 pixel is 1 byte)\n",
    "        out_file.write(img_file.read(28*28*10))\n",
    "        img_file.close()\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW Inference with W1A1:\n",
      "Setting network weights and thresholds in accelerator...\n",
      "Running prebinarized test for 10 images...\n",
      "Inference took 791834 microseconds, 79183.4 usec per image\n",
      "Classification rate: 12.6289 images per second\n",
      "Inference took 791833.98 microseconds, 79183.40 usec per image\n",
      "Classification rate: 12.63 images per second\n",
      "\n",
      "SW Inference with W1A2:\n",
      "Setting network weights and thresholds in accelerator...\n",
      "Running prebinarized test for 10 images...\n",
      "Inference took 3864594 microseconds, 386459 usec per image\n",
      "Inference took 3864594.06 microseconds, 386459.41 usec per image\n",
      "Classification rate: 2.59 images per second\n",
      "Classification rate: 2.58759 images per second\n"
     ]
    }
   ],
   "source": [
    "print(\"SW Inference with W1A1:\")\n",
    "sw_lfcW1A1_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1,\"mnist\",bnn.RUNTIME_SW)\n",
    "sw_resultW1A1 = sw_lfcW1A1_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\")\n",
    "print(\"\\nSW Inference with W1A2:\")\n",
    "sw_lfcW1A2_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A2,\"mnist\",bnn.RUNTIME_SW)\n",
    "sw_resultW1A2 = sw_lfcW1A2_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, pure software runtime is much slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "### Inference time\n",
    "\n",
    "##### Hardware\n",
    "\n",
    "Results can be visualized using matplotlib. The inference time per image is accessible through the classifier. Here you can see hardware vs software execution times per image in microseconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hw_time = [lfcW1A1_classifier.usecPerImage,\n",
    "           lfcW1A2_classifier.usecPerImage]\n",
    "sw_time = [sw_lfcW1A1_classifier.usecPerImage,\n",
    "           sw_lfcW1A2_classifier.usecPerImage]\n",
    "\n",
    "x_axis = ('W1A1', 'W1A2')\n",
    "\n",
    "y_pos = np.arange(len(x_axis))\n",
    "plt.bar(y_pos-0.25, hw_time, 0.25)\n",
    "plt.bar(y_pos+0.25, sw_time, 0.25)\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.legend([\"hardware\",\"software\"])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy W1A1:  98.4\n",
      "Accuracy W1A2:  98.49\n"
     ]
    }
   ],
   "source": [
    "#compare against labels\n",
    "countRight = 0\n",
    "for idx in range(len(labels)):\n",
    "    if labels[idx] == result_W1A1[idx]:\n",
    "        countRight += 1\n",
    "accuracyW1A1 = countRight*100/len(labels)\n",
    "\n",
    "countRight = 0\n",
    "for idx in range(len(labels)):\n",
    "    if labels[idx] == result_W1A2[idx]:\n",
    "        countRight += 1\n",
    "accuracyW1A2 = countRight*100/len(labels)\n",
    "\n",
    "print(\"Accuracy W1A1: \", accuracyW1A1)\n",
    "print(\"Accuracy W1A2: \", accuracyW1A2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
